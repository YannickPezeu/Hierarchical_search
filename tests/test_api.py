# tests/test_api.py
import os
import shutil
import time
import json
import pytest
from fastapi.testclient import TestClient

from src.main import app

# --- Constantes pour les tests ---
TEST_INDEX_ID = "test_library"
TEST_PASSWORD = "supersecret"
TEST_API_KEY = os.getenv("INTERNAL_API_KEY", "test-api-key-for-local-testing")
TEST_USER_GROUPS = ["test-group-1", "test-group-2"]

INDEXES_DIR = "./all_indexes"
TEST_INDEX_PATH = os.path.join(INDEXES_DIR, TEST_INDEX_ID)
SOURCE_FILES_DIR = os.path.join(TEST_INDEX_PATH, 'source_files')
print("SOURCE_FILES_DIR", os.path.abspath(SOURCE_FILES_DIR))


@pytest.fixture(scope="module")
def client():
    """Client de test FastAPI"""
    with TestClient(app) as c:
        yield c


@pytest.fixture(scope="module")
def api_key_header():
    """Header avec uniquement l'API key (sans Content-Type)"""
    return {"X-API-Key": TEST_API_KEY}


@pytest.fixture(scope="module")
def api_headers_json():
    """Headers avec l'API key pour les requ√™tes JSON"""
    return {
        "X-API-Key": TEST_API_KEY,
        "Content-Type": "application/json"
    }


@pytest.fixture(scope="module", autouse=True)
def setup_teardown_session():
    """
    Nettoie les anciens r√©sultats de test avant l'ex√©cution.
    """
    # Liste des √©l√©ments √† supprimer
    items_to_remove = ["index", ".pw_hash", ".groups.json", "md_files"]

    for item_name in items_to_remove:
        path_to_remove = os.path.join(TEST_INDEX_PATH, item_name)
        if os.path.exists(path_to_remove):
            if os.path.isdir(path_to_remove):
                shutil.rmtree(path_to_remove)
            else:
                os.remove(path_to_remove)

    print(f"\n‚úÖ Nettoyage effectu√© pour {TEST_INDEX_PATH}")

    yield  # Les tests s'ex√©cutent ici


import time
import json
import os

import time


def wait_for_indexing_completion(
        client,
        index_id: str,
        api_headers: dict,
        timeout: int = 120,
        poll_interval: int = 2
) -> dict:
    """
    Attend que l'indexation soit termin√©e en interrogeant l'API de statut.

    Args:
        client: TestClient FastAPI
        index_id: Identifiant de l'index
        api_headers: Headers avec l'API key
        timeout: Temps maximum d'attente en secondes (d√©faut: 120s)
        poll_interval: Intervalle entre chaque v√©rification en secondes (d√©faut: 2s)

    Returns:
        dict: Statut final de l'indexation

    Raises:
        TimeoutError: Si l'indexation n'est pas termin√©e dans le temps imparti
        Exception: Si l'indexation a √©chou√©
    """
    start_time = time.time()

    print(f"\n‚è≥ Attente de la fin de l'indexation (timeout: {timeout}s)...")

    while True:
        elapsed = time.time() - start_time

        # V√©rifier le timeout
        if elapsed > timeout:
            raise TimeoutError(
                f"L'indexation n'est pas termin√©e apr√®s {timeout}s. "
                f"Augmentez le timeout ou v√©rifiez les logs."
            )

        # Interroger l'API de statut
        response = client.get(
            f"/index/{index_id}/status",
            headers=api_headers
        )

        if response.status_code != 200:
            print(f"  [‚ö†Ô∏è] Erreur lors de la v√©rification du statut: {response.status_code}")
            time.sleep(poll_interval)
            continue

        status_data = response.json()
        status = status_data.get("status")

        if status == "completed":
            duration = status_data.get("duration_seconds", 0)
            num_docs = status_data.get("num_documents", "?")
            print(f"  ‚úÖ Indexation termin√©e en {duration:.1f}s ({num_docs} documents)")
            return status_data

        elif status == "failed":
            error = status_data.get("error", "Unknown error")
            error_type = status_data.get("error_type", "")
            raise Exception(f"L'indexation a √©chou√© ({error_type}): {error}")

        elif status == "in_progress":
            print(f"  [{elapsed:.1f}s] Indexation en cours...")
            time.sleep(poll_interval)

        elif status == "not_found":
            print(f"  [{elapsed:.1f}s] Attente du d√©marrage de l'indexation...")
            time.sleep(poll_interval)

        else:
            print(f"  [‚ö†Ô∏è] Statut inconnu: {status}")
            time.sleep(poll_interval)


@pytest.mark.dependency()
def test_create_index_from_existing_files(client, api_key_header):
    """
    Teste la cr√©ation d'un index en utilisant les fichiers PDF
    plac√©s manuellement dans le dossier source.
    """
    print('Source Files dir:', os.path.realpath(SOURCE_FILES_DIR))
    assert os.path.exists(SOURCE_FILES_DIR), f"Dossier source introuvable: '{SOURCE_FILES_DIR}'"
    print(f"\nüìÅ Dossier des fichiers source : '{SOURCE_FILES_DIR}'")
    pdf_files = [f for f in os.listdir(SOURCE_FILES_DIR) if f.endswith('.pdf')]
    print(f"üìÑ Fichiers PDF trouv√©s : {pdf_files}")
    assert len(pdf_files) > 0, f"Aucun PDF trouv√© dans '{SOURCE_FILES_DIR}'."

    files_to_upload = []
    metadata = {}
    open_files = []

    try:
        # Pr√©parer la liste des fichiers √† uploader
        for filename in pdf_files:
            file_path = os.path.join(SOURCE_FILES_DIR, filename)
            file_handle = open(file_path, 'rb')
            open_files.append(file_handle)
            files_to_upload.append(('files', (filename, file_handle, 'application/pdf')))
            metadata[filename] = f"http://example.com/docs/{filename}"

        print('files_to_upload:', [f[1][0] for f in files_to_upload])

        # Envoyer la requ√™te avec l'API key et les groupes
        response = client.post(
            f"/index/{TEST_INDEX_ID}",
            files=files_to_upload,
            data={
                "metadata_json": json.dumps(metadata),
                "password": TEST_PASSWORD,
                "groups": json.dumps(TEST_USER_GROUPS)
            },
            headers=api_key_header
        )
    finally:
        for f in open_files:
            f.close()

    if response.status_code != 202:
        print("R√©ponse de l'API (erreur):", response.json())
    assert response.status_code == 202

    # ‚úÖ NOUVEAU : Attendre intelligemment la fin de l'indexation via l'API
    try:
        status_data = wait_for_indexing_completion(
            client=client,
            index_id=TEST_INDEX_ID,
            api_headers=api_key_header,
            timeout=120,  # 2 minutes max
            poll_interval=2  # V√©rifier toutes les 2 secondes
        )
        print(f"üìä Statut final: {status_data}")
    except TimeoutError as e:
        pytest.fail(str(e))
    except Exception as e:
        pytest.fail(f"Indexation √©chou√©e: {e}")

    # V√©rifications
    index_dir_path = os.path.join(TEST_INDEX_PATH, "index")
    assert os.path.exists(index_dir_path), "Le dossier 'index' n'a pas √©t√© cr√©√©"

    # V√©rifier qu'il y a des nodes dans le docstore
    docstore_file = os.path.join(index_dir_path, "docstore.json")
    assert os.path.exists(docstore_file), "Le fichier docstore.json n'existe pas"

    with open(docstore_file, 'r') as f:
        docstore_data = json.load(f)
        num_nodes = len(docstore_data.get("docstore/data", {}))
        print(f"üì¶ Nodes dans le docstore: {num_nodes}")
        assert num_nodes > 0, "Aucun node n'a √©t√© cr√©√© dans l'index"

    # V√©rifier que le fichier .groups.json existe
    groups_file = os.path.join(TEST_INDEX_PATH, ".groups.json")
    assert os.path.exists(groups_file), "Le fichier .groups.json n'a pas √©t√© cr√©√©"

    # V√©rifier le contenu du fichier .groups.json
    with open(groups_file, "r") as f:
        groups_data = json.load(f)
        assert groups_data.get("groups") == TEST_USER_GROUPS
        print(f"‚úÖ Groupes autoris√©s v√©rifi√©s: {groups_data['groups']}")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_get_indexing_status(client, api_key_header):
    """Test de l'endpoint de statut apr√®s indexation r√©ussie"""
    response = client.get(
        f"/index/{TEST_INDEX_ID}/status",
        headers=api_key_header
    )

    assert response.status_code == 200
    status_data = response.json()

    assert status_data["status"] == "completed"
    assert status_data["num_documents"] > 0
    assert status_data["duration_seconds"] > 0

    print(f"\n‚úÖ Statut r√©cup√©r√© avec succ√®s:")
    print(f"   - Statut: {status_data['status']}")
    print(f"   - Documents: {status_data['num_documents']}")
    print(f"   - Dur√©e: {status_data['duration_seconds']:.1f}s")


@pytest.mark.dependency()
def test_get_status_nonexistent_index(client, api_key_header):
    """Test de l'endpoint de statut pour un index qui n'existe pas"""
    response = client.get(
        f"/index/nonexistent_library/status",
        headers=api_key_header
    )

    assert response.status_code == 200
    status_data = response.json()
    assert status_data["status"] == "not_found"

    print(f"\n‚úÖ Statut 'not_found' retourn√© correctement pour un index inexistant")



@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_index_success(client, api_headers_json):
    """Test de recherche avec les bons groupes"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "Quels sont les taux d'overhead ?",
            "user_groups": TEST_USER_GROUPS,
            "password": TEST_PASSWORD
        },
        headers=api_headers_json
    )

    if response.status_code != 200:
        print("Erreur:", response.json())

    assert response.status_code == 200
    results = response.json()
    assert len(results) > 0
    print(f"\n‚úÖ {len(results)} r√©sultats trouv√©s")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_wrong_password(client, api_headers_json):
    """Test avec un mauvais mot de passe"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "test",
            "user_groups": TEST_USER_GROUPS,
            "password": "wrongpassword"
        },
        headers=api_headers_json
    )
    assert response.status_code == 403
    print("\n‚úÖ Mot de passe incorrect refus√©")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_wrong_groups(client, api_headers_json):
    """Test avec des groupes non autoris√©s"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "test",
            "user_groups": ["wrong-group", "another-wrong-group"],
            "password": TEST_PASSWORD
        },
        headers=api_headers_json
    )
    assert response.status_code == 403
    error_detail = response.json()
    assert "Access denied" in error_detail.get("detail", "")
    print(f"\n‚úÖ Acc√®s refus√© comme attendu: {error_detail['detail']}")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_without_api_key(client):
    """Test sans API key (devrait √©chouer)"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "test",
            "user_groups": TEST_USER_GROUPS,
            "password": TEST_PASSWORD
        }
    )
    assert response.status_code == 422  # FastAPI retourne 422 si header manquant
    print(f"\n‚úÖ Requ√™te sans API key refus√©e: {response.status_code}")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_with_wrong_api_key(client):
    """Test avec une mauvaise API key"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "test",
            "user_groups": TEST_USER_GROUPS,
            "password": TEST_PASSWORD
        },
        headers={
            "X-API-Key": "wrong-api-key",
            "Content-Type": "application/json"
        }
    )
    assert response.status_code == 403
    print("\n‚úÖ Requ√™te avec mauvaise API key refus√©e")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_multiple_queries(client, api_headers_json):
    """Test avec plusieurs requ√™tes diff√©rentes"""
    queries = [
        "Quels sont les taux d'overhead ?",
        "r√®glement financier",
        "budget"
    ]

    for query in queries:
        response = client.post(
            f"/search/{TEST_INDEX_ID}",
            json={
                "query": query,
                "user_groups": TEST_USER_GROUPS,
                "password": TEST_PASSWORD
            },
            headers=api_headers_json
        )

        assert response.status_code == 200
        results = response.json()
        print(f"\nüîç Query: '{query}' -> {len(results)} r√©sultats")

        # Afficher les 2 premiers r√©sultats
        for i, result in enumerate(results[:2], 1):
            print(f"  {i}. {result.get('title', 'Sans titre')} (score: {result.get('score', 0):.3f})")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_with_one_matching_group(client, api_headers_json):
    """Test avec un seul groupe correspondant (devrait r√©ussir)"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "test",
            "user_groups": ["test-group-1", "some-other-group"],  # Un seul groupe match
            "password": TEST_PASSWORD
        },
        headers=api_headers_json
    )
    assert response.status_code == 200
    print("\n‚úÖ Acc√®s autoris√© avec un seul groupe correspondant")


@pytest.mark.dependency(depends=["test_create_index_from_existing_files"])
def test_search_no_password_when_required(client, api_headers_json):
    """Test sans mot de passe quand il est requis"""
    response = client.post(
        f"/search/{TEST_INDEX_ID}",
        json={
            "query": "test",
            "user_groups": TEST_USER_GROUPS
            # Pas de password
        },
        headers=api_headers_json
    )
    assert response.status_code == 401
    print("\n‚úÖ Mot de passe manquant d√©tect√©")


@pytest.mark.dependency()
def test_corrupted_and_valid_pdf_handling(client, api_key_header):
    """
    Teste que :
    1. Les PDFs corrompus sont d√©tect√©s, supprim√©s et ne sont pas index√©s
    2. Les PDFs valides passent la validation et sont index√©s correctement
    """
    # Setup : chemins des fichiers de test
    test_data_dir = "tests/data"
    corrupted_pdf_source = os.path.join(test_data_dir, "corruptedPDF.pdf")
    valid_pdf_source = os.path.join(test_data_dir, "validPDF.pdf")

    # V√©rifier que les fichiers de test existent
    assert os.path.exists(corrupted_pdf_source), f"Fichier de test manquant: {corrupted_pdf_source}"
    assert os.path.exists(valid_pdf_source), f"Fichier de test manquant: {valid_pdf_source}"

    print(f"\nüìã Test de validation PDF")
    print(f"   - PDF corrompu : {corrupted_pdf_source}")
    print(f"   - PDF valide : {valid_pdf_source}")

    # Cr√©er un index temporaire pour ce test
    test_index_id = "test_pdf_validation"
    test_index_path = os.path.join(INDEXES_DIR, test_index_id)

    # Nettoyer si existe d√©j√†
    if os.path.exists(test_index_path):
        shutil.rmtree(test_index_path)
        print(f"   - Nettoyage de l'index pr√©c√©dent")

    # Pr√©parer l'upload (on copie pour ne pas perdre les originaux)
    files_to_upload = []
    metadata = {}
    open_files = []

    try:
        # Copier et ouvrir le PDF corrompu
        with open(corrupted_pdf_source, 'rb') as src:
            corrupted_content = src.read()

        # Cr√©er un fichier temporaire pour le PDF corrompu
        import tempfile
        corrupted_temp = tempfile.NamedTemporaryFile(delete=False, suffix='_corruptedPDF_copy.pdf')
        corrupted_temp.write(corrupted_content)
        corrupted_temp.close()

        # Copier et ouvrir le PDF valide
        with open(valid_pdf_source, 'rb') as src:
            valid_content = src.read()

        valid_temp = tempfile.NamedTemporaryFile(delete=False, suffix='_validPDF_copy.pdf')
        valid_temp.write(valid_content)
        valid_temp.close()

        # Pr√©parer les fichiers pour l'upload
        corrupted_handle = open(corrupted_temp.name, 'rb')
        valid_handle = open(valid_temp.name, 'rb')
        open_files.extend([corrupted_handle, valid_handle])

        files_to_upload.append(('files', ('corruptedPDF_copy.pdf', corrupted_handle, 'application/pdf')))
        files_to_upload.append(('files', ('validPDF_copy.pdf', valid_handle, 'application/pdf')))

        metadata['corruptedPDF_copy.pdf'] = "http://example.com/test/corrupted.pdf"
        metadata['validPDF_copy.pdf'] = "http://example.com/test/valid.pdf"

        print(f"üì§ Envoi de 2 fichiers (1 corrompu + 1 valide)...")

        # Envoyer la requ√™te
        response = client.post(
            f"/index/{test_index_id}",
            files=files_to_upload,
            data={
                "metadata_json": json.dumps(metadata),
                "groups": json.dumps(["test-pdf-group"])
            },
            headers=api_key_header
        )
    finally:
        # Fermer les fichiers
        for f in open_files:
            f.close()
        # Supprimer les fichiers temporaires
        try:
            os.unlink(corrupted_temp.name)
            os.unlink(valid_temp.name)
        except:
            pass

    assert response.status_code == 202, f"Indexation non accept√©e: {response.json()}"
    print(f"   ‚úÖ Requ√™te d'indexation accept√©e (202)")

    # Attendre la fin de l'indexation
    try:
        status_data = wait_for_indexing_completion(
            client=client,
            index_id=test_index_id,
            api_headers=api_key_header,
            timeout=120,
            poll_interval=2
        )
    except Exception as e:
        # Afficher les logs si disponibles
        if os.path.exists(test_index_path):
            status_file = os.path.join(test_index_path, ".indexing_status")
            if os.path.exists(status_file):
                with open(status_file, 'r') as f:
                    print(f"\n‚ö†Ô∏è Statut d'indexation: {f.read()}")
        pytest.fail(f"Erreur lors de l'indexation: {e}")

    # V√âRIFICATIONS
    print(f"\nüîç V√©rification des r√©sultats...")

    # 1. V√©rifier que le PDF corrompu n'est PAS dans l'archive
    archive_dir = os.path.join(test_index_path, "source_files_archive")
    archived_corrupted = os.path.join(archive_dir, "corruptedPDF_copy.pdf")

    if os.path.exists(archived_corrupted):
        pytest.fail("‚ùå Le PDF corrompu ne devrait PAS √™tre archiv√© (il devrait avoir √©t√© supprim√©)")
    print("   ‚úÖ PDF corrompu non archiv√© (supprim√© comme attendu)")

    # 2. V√©rifier que le PDF valide EST dans l'archive
    archived_valid = os.path.join(archive_dir, "validPDF_copy.pdf")
    if not os.path.exists(archived_valid):
        # Lister le contenu de l'archive pour debug
        if os.path.exists(archive_dir):
            print(f"\n   üìÅ Contenu de {archive_dir}:")
            for item in os.listdir(archive_dir):
                print(f"      - {item}")
        pytest.fail("‚ùå Le PDF valide devrait √™tre archiv√©")
    print("   ‚úÖ PDF valide archiv√© correctement")

    # 3. V√©rifier que le markdown du PDF valide a √©t√© cr√©√©
    md_dir = os.path.join(test_index_path, "md_files")
    valid_md = os.path.join(md_dir, "validPDF_copy.md")
    if not os.path.exists(valid_md):
        # Lister le contenu pour debug
        if os.path.exists(md_dir):
            print(f"\n   üìÅ Contenu de {md_dir}:")
            for item in os.listdir(md_dir):
                print(f"      - {item}")
        pytest.fail("‚ùå Le markdown du PDF valide devrait exister")
    print("   ‚úÖ Markdown cr√©√© pour le PDF valide")

    # 4. V√©rifier que le markdown du PDF corrompu n'existe PAS
    corrupted_md = os.path.join(md_dir, "corruptedPDF_copy.md")
    if os.path.exists(corrupted_md):
        pytest.fail("‚ùå Le markdown du PDF corrompu ne devrait PAS exister")
    print("   ‚úÖ Aucun markdown pour le PDF corrompu (comme attendu)")

    # 5. V√©rifier le nombre de documents index√©s dans le statut
    num_docs = status_data.get("num_documents", 0)
    if num_docs != 1:
        pytest.fail(f"‚ùå Devrait avoir index√© 1 document (le valide), mais a index√© {num_docs}")
    print(f"   ‚úÖ Nombre de documents index√©s: {num_docs} (correct)")

    # 6. V√©rifier que les nodes du PDF valide sont dans l'index
    index_dir = os.path.join(test_index_path, "index")
    docstore_file = os.path.join(index_dir, "docstore.json")

    if os.path.exists(docstore_file):
        with open(docstore_file, 'r') as f:
            docstore_data = json.load(f)
            num_nodes = len(docstore_data.get("docstore/data", {}))
            print(f"   ‚úÖ Nodes index√©s: {num_nodes}")
            if num_nodes == 0:
                pytest.fail("‚ùå Aucun node trouv√© pour le PDF valide")
    else:
        pytest.fail(f"‚ùå Docstore introuvable: {docstore_file}")

    # 7. V√©rifier que le contenu du markdown est correct (pas vide)
    with open(valid_md, 'r', encoding='utf-8') as f:
        md_content = f.read()
        if len(md_content) < 50:
            pytest.fail(f"‚ùå Le markdown du PDF valide est trop court ({len(md_content)} chars)")
        print(f"   ‚úÖ Markdown du PDF valide contient {len(md_content)} caract√®res")

    print(f"\n{'=' * 80}")
    print(f"‚úÖ TEST DE VALIDATION PDF R√âUSSI")
    print(f"{'=' * 80}")
    print(f"   üìä R√©sum√©:")
    print(f"      - PDF corrompu : d√©tect√© et rejet√© ‚úì")
    print(f"      - PDF corrompu : supprim√© du syst√®me ‚úì")
    print(f"      - PDF valide : valid√© et archiv√© ‚úì")
    print(f"      - PDF valide : converti en markdown ‚úì")
    print(f"      - PDF valide : index√© ({num_nodes} nodes) ‚úì")
    print(f"{'=' * 80}\n")

    # Cleanup
    if os.path.exists(test_index_path):
        shutil.rmtree(test_index_path)
        print(f"üßπ Nettoyage de l'index de test effectu√©")


