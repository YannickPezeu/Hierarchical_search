#!/bin/bash
set -e

# â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LIBRARY_NAME="${LIBRARY_NAME:-large_campus2}"
BASE_DIR="/app/all_indexes"
LIVE_DIR="${BASE_DIR}/${LIBRARY_NAME}"
NEW_DIR="${BASE_DIR}/${LIBRARY_NAME}_new"
OLD_DIR="${BASE_DIR}/${LIBRARY_NAME}_old"

echo "============================================="
echo "  EPFL Scraper â€” Fresh Dump + Swap"
echo "============================================="
echo "  LIVE : ${LIVE_DIR}"
echo "  NEW  : ${NEW_DIR}"
echo "  OLD  : ${OLD_DIR}"
echo "============================================="

# â”€â”€ Cleanup any leftover partial run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if [ -d "${NEW_DIR}" ]; then
    echo "âš ï¸  Found leftover ${NEW_DIR} from a previous failed run."
    echo "   Checking for crawler state to resume..."
    if [ -f "${NEW_DIR}/source_files/crawler_state.json" ]; then
        echo "   âœ“ State file found â€” resuming previous scrape."
    else
        echo "   âœ— No state file â€” cleaning up and starting fresh."
        rm -rf "${NEW_DIR}"
    fi
fi

# â”€â”€ Run the scraper into the _new directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸš€ Starting scraper into ${LIBRARY_NAME}_new ..."
node epfl-hierarchical-scraper.js "${LIBRARY_NAME}_new" "$@"

# â”€â”€ Verify the scrape produced data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FILE_COUNT=$(find "${NEW_DIR}" -type f | wc -l)
echo ""
echo "ğŸ“Š Scrape complete: ${FILE_COUNT} files in new directory."

if [ "${FILE_COUNT}" -lt 10 ]; then
    echo "âŒ Too few files (${FILE_COUNT}). Scrape likely failed. Keeping old data."
    exit 1
fi

# â”€â”€ Generate reindex manifest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
if [ -d "${LIVE_DIR}" ]; then
    echo "ğŸ“‹ Comparing old and new scrape to generate reindex manifest..."
    node generate-reindex-manifest.js \
        "${LIVE_DIR}/source_files" \
        "${NEW_DIR}/source_files" \
        "${NEW_DIR}/reindex_manifest.json"
else
    echo "ğŸ“‹ No previous scrape found â€” all pages will be marked for indexing."
    # Generate manifest with everything as "added"
    node generate-reindex-manifest.js \
        "/tmp/empty_dir" \
        "${NEW_DIR}/source_files" \
        "${NEW_DIR}/reindex_manifest.json"
fi

# â”€â”€ Atomic swap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸ”„ Swapping directories..."

# Remove previous old backup if it exists
if [ -d "${OLD_DIR}" ]; then
    echo "   Removing previous backup ${OLD_DIR}..."
    rm -rf "${OLD_DIR}"
fi

# Move current live â†’ old (if it exists)
if [ -d "${LIVE_DIR}" ]; then
    echo "   ${LIBRARY_NAME} â†’ ${LIBRARY_NAME}_old"
    mv "${LIVE_DIR}" "${OLD_DIR}"
fi

# Move new â†’ live
echo "   ${LIBRARY_NAME}_new â†’ ${LIBRARY_NAME}"
mv "${NEW_DIR}" "${LIVE_DIR}"

# Delete old
if [ -d "${OLD_DIR}" ]; then
    echo "   Deleting ${LIBRARY_NAME}_old..."
    rm -rf "${OLD_DIR}"
fi

echo ""
echo "âœ… Swap complete. Live data is now fresh."
echo "   Files: $(find "${LIVE_DIR}" -type f | wc -l)"
echo "   Manifest: ${LIVE_DIR}/reindex_manifest.json"
echo "============================================="